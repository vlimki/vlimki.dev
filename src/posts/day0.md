---
title: "Becoming a Cracked Engineer - Day 0 of ML"
description: "The start of my plan to become a machine learning engineer."
published: true
date: '2024-06-07'
slug: 'day0'
tags: ['journey']
---

I think there's something motivating about the idea of being so good at a subject that it's almost inhumane. That's precisely what the term "cracked" describes - a term that has been floating around in the engineering space on X. To have an understanding of a subject so deep and so broad that nobody can compete. I couldn't help but to become motivated by these small-to-medium-sized X accounts who casually put like 8-11 hours into ML **per day**. Really? THAT's my competition? My efforts haven't been even close to deliberate enough to stand a chance against some of these people.

I recently saw Andrej Karpathy on the Lex Fridman podcast talking about his [advice for ML beginners](https://www.youtube.com/watch?v=I2ZK3ngNvvI). His advice could be summarized into the two following points:

1. There is <b>no universal resource</b> for learning ML.
2. Learning ML is about <b>the amount of time spent</b>. It is less important to be doing the right thing than it is just to be doing something.

He specifically talks about the **10,000-hour figure** that is required to master any skill. Like, spending time on the subject is of inherent value.
Point two was also influenced by the following philosophy:
> "You will waste time doing something wrong. You will eventually figure out it's not right and you will accumulate scar tissue."

Obviously too much of anything will automatically turn into a net negative. You should definitely have a plan in mind and at least briefly consider the resources you'll be using to learn. I think the key takeaway would just be to **not get stuck** contemplating whether a resource is really the right one (referred to as paralysis in the podcast). Karpathy also talked about the importance of code-based learning in the interview. He says that building and using code to learn is more effective than just notes or mathematical notation.

Practical steps one can take from this advice:
- Strive to spend the 10,000 hours.
- Focus on forming a daily habit of learning ML.
- Do your learning in a code-centric manner.

Following this advice, I feel like the best way to start moving from my ML plateau would be to just take action. I'm going to start documenting **everything** I learn in ML - simple or advanced - on this website and [on X](https://x.com/vlimkidev/). I saw someone else doing it on X too and their progress motivated me insanely much. Like, really. Had I put that much effort in ML - even for a month - I'd be insanely far right now.

Here's a list of resources I plan on using:
- [Mathematics for Machine Learning](https://mml-book.github.io/)
- [Thomas' Calculus, Early Transcendentals - 15th edition](https://www.amazon.com/Thomas-Calculus-Early-Transcendentals-Units/dp/1292725907/)
- [Linear Algebra and Its Applications](https://www.amazon.com/Linear-Algebra-Its-Applications-4th/dp/0030105676/)
- [Probability and Statistics for Machine Learning](https://link.springer.com/book/10.1007/978-3-031-53282-5)
- [The Hundred-Page Machine Learning Book](https://themlbook.com/)
